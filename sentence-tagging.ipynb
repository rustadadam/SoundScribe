{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "71ab7b92-631d-489f-b89f-fcd99e7f9b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 06:09:43.106313: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 06:09:43.120230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-13 06:09:43.138844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-13 06:09:43.144645: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-13 06:09:43.157792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "from sagemaker.model_metrics import ModelMetrics\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker import ModelPackage, Session\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker.model import Model\n",
    "from pathlib import Path\n",
    "\n",
    "import sagemaker\n",
    "import logging\n",
    "import torch\n",
    "import boto3\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_state": "idle",
   "id": "4e837c07-42fe-4694-9a0d-f1d70d34a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session and clients\n",
    "sagemaker_session = Session()\n",
    "role = sagemaker.get_execution_role()  # IAM role\n",
    "region = boto3.Session().region_name\n",
    "sm_client = boto3.client('sagemaker')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_state": "idle",
   "id": "d0a55c52-3c77-4101-898c-ea5f6e9efe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_path = Path('book-text-info/frankenstein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_state": "idle",
   "id": "d531c067-0db0-4881-8034-6fcd24b8c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_text = book_path.joinpath(f'{book_path.name}-book-audio-text.txt')\n",
    "if 'alice' in book_path.name or 'frank' in book_path.name:\n",
    "    with open(book_text) as f:\n",
    "        lines = f.read()\n",
    "else:\n",
    "    with open(book_text) as f:\n",
    "        lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719919f9-9ffe-41e5-9a3c-dafe991668ca",
   "metadata": {},
   "source": [
    "Clean the text if it is in paragraph form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_state": "idle",
   "id": "e9d69181-ad40-448b-b1bd-19ea7bc8142e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if isinstance(lines, str):\n",
    "    new_lines = []\n",
    "\n",
    "    old_lines = lines.split('\\n')\n",
    "    start = True\n",
    "    one_liner = ''\n",
    "    for line in old_lines:\n",
    "        # group by paragraphs\n",
    "        if len(line.strip()) == 0:\n",
    "            new_lines.append(one_liner)\n",
    "            one_liner = ''\n",
    "            continue\n",
    "        one_liner += line.strip() + ' '\n",
    "    lines = new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_state": "idle",
   "id": "f00cf10f-db27-41af-bd0f-8906439b18df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./working-voices.json']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice_bucket = 's3://sound-scribe-acessories/working-voices.json'\n",
    "downloader = S3Downloader()\n",
    "downloader.download(voice_bucket, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_state": "idle",
   "id": "7cd1050b-bd7f-47e1-ad7b-f4c058ab8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_path = book_path.joinpath(f'{book_path.name}-person-quotes.json')\n",
    "with open(quote_path) as f:\n",
    "    person_quotes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "execution_state": "idle",
   "id": "ab3bd09d-a0fe-4fca-a52d-db2c8aca1235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unknown': 'en-US-Neural2-A',\n",
       " 'I': 'en-US-Neural2-C',\n",
       " 'Elizabeth': 'en-US-Neural2-D',\n",
       " 'our': 'en-US-Neural2-E',\n",
       " 'Clerval': 'en-US-Neural2-F',\n",
       " 'the professor': 'en-US-Neural2-G',\n",
       " 'M. Krempe': 'en-US-Neural2-H',\n",
       " 'This professor': 'en-US-Neural2-I',\n",
       " 'M. Waldman': 'en-US-Neural2-J',\n",
       " 'Coleridge': 'en-US-Standard-A',\n",
       " 'Ernest': 'en-US-Standard-B',\n",
       " 'Justine': 'en-US-Standard-E',\n",
       " 'Alas': 'en-US-Standard-J',\n",
       " 'him': 'en-US-Studio-O',\n",
       " 'Wordsworth': 'en-US-Studio-Q',\n",
       " 'an old woman who was sleeping in a chair beside me': 'en-GB-Standard-A',\n",
       " 'my enemy': 'en-GB-Standard-B',\n",
       " 'Frankenstein': 'en-GB-Standard-C',\n",
       " 'Project Gutenberg': 'en-GB-Standard-D',\n",
       " 'PGLAF': 'en-GB-Standard-F'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('working-voices.json') as f:\n",
    "    voices = json.load(f)\n",
    "\n",
    "narrator = \"en-US-Polyglot-1\"\n",
    "\n",
    "voices = voices['voices']\n",
    "voices.remove(narrator)\n",
    "\n",
    "voice_name = {name: voices[i % len(voices)] for i, name in enumerate(person_quotes)}\n",
    "\n",
    "voice_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "execution_state": "idle",
   "id": "0c7217cb-87e1-407b-85ce-64a7d3a2620f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "replace_counts = {name: 0 for name, quotes in person_quotes.items()}\n",
    "new_lines = ['<speak>\\n']\n",
    "for line in lines:\n",
    "    new_line = ''\n",
    "    pattern = r\"</[a-zA-Z ’]+>\"\n",
    "    # Find all the name tags\n",
    "    res = re.findall(pattern, line)\n",
    "    if len(res) == 0:\n",
    "        new_lines.append(line)\n",
    "        continue\n",
    "\n",
    "    pattern = r\"“[’a-zA-Z \\[\\],?!.\\—:\\(\\)_”]*\"\n",
    "    words = re.findall(pattern, line)\n",
    "    # print(line)\n",
    "    # print(words)\n",
    "    start = 0\n",
    "    for r, w in zip(res, words):\n",
    "        # Get the index of the start of </name>\n",
    "        r_idx = line.index(r)\n",
    "        # Add all characters up until that point\n",
    "        new_line += line[start:r_idx]\n",
    "        # Update start to point to the end of r\n",
    "        start += len(r) + r_idx\n",
    "\n",
    "        # Get the index of the quote\n",
    "        w_idx = line.index(w)\n",
    "        # Add all characters from the end of the </name> to the quote\n",
    "        new_line += line[start:w_idx]\n",
    "\n",
    "        # Extract the name from the </name>\n",
    "        name = r[2:-1]\n",
    "        # Get the index from the quote gathering dictionary\n",
    "        idx = replace_counts[name]\n",
    "        # Get a random voice\n",
    "        tts_voice = voice_name[name]\n",
    "        try:\n",
    "            # Surround the quote in the proper voice tags\n",
    "            voice_quote = f'<voice name=\"{tts_voice}\">{person_quotes[name][idx]}</voice>'\n",
    "            # Substitute the quote with the tagged quote\n",
    "            s = re.sub(pattern, w, voice_quote)\n",
    "            # Update the new_line to include this information\n",
    "            new_line += s\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        # Update start to point at the end of the quote\n",
    "        start += len(w) + w_idx\n",
    "        # Update replace counts to make sure we get all the quotes\n",
    "        replace_counts[name] += 1\n",
    "    # Add the rest of the line to the new line\n",
    "    new_line += line[start:]\n",
    "    new_line += '\\n'\n",
    "    new_lines.append(new_line)\n",
    "new_lines.append('</speak>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "execution_state": "idle",
   "id": "4887b4e2-6498-4af8-975b-8f093a48fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_path = book_path.joinpath(f'{book_path.name}-book-audio-text-tagged.txt')\n",
    "with open(tagged_path, 'w') as f:\n",
    "    f.writelines(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "execution_state": "idle",
   "id": "892fe02a-67d6-4f5b-a4a7-085002ad6f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://book-text-info/frankenstein/frankenstein-book-audio-text-tagged.txt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_bucket = f's3://book-text-info/{book_path.name}'\n",
    "uploader = S3Uploader()\n",
    "uploader.upload(tagged_path, quote_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b662e7-4dd6-47ef-8877-49e66dec6709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
